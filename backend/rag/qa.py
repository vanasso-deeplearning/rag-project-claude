"""
RAG ì§ˆì˜ì‘ë‹µ ëª¨ë“ˆ
Multi-Knowledge Retrieval ë°©ì‹ìœ¼ë¡œ ë³µìˆ˜ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
"""

import os
from typing import List, Dict, Any, Tuple
from pathlib import Path
import hashlib

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.schema import Document
from langchain.prompts import ChatPromptTemplate


def get_collection_name(knowledge_name: str) -> str:
    """ì§€ì‹ëª…ìœ¼ë¡œë¶€í„° ChromaDB collection ì´ë¦„ ìƒì„±"""
    hash_suffix = hashlib.md5(knowledge_name.encode('utf-8')).hexdigest()[:8]
    return f"kb_{hash_suffix}"


def get_retriever(knowledge_name: str, top_k: int = 3):
    """ë‹¨ì¼ ì§€ì‹ë² ì´ìŠ¤ì˜ retriever ìƒì„±"""
    base_dir = Path("document_sets") / knowledge_name
    chroma_dir = base_dir / "chroma_db"
    
    if not chroma_dir.exists():
        raise ValueError(f"ì§€ì‹ '{knowledge_name}'ì˜ ì„ë² ë”©ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    collection_name = get_collection_name(knowledge_name)
    
    vectorstore = Chroma(
        collection_name=collection_name,
        embedding_function=embeddings,
        persist_directory=str(chroma_dir)
    )
    
    # as_retriever() ëŒ€ì‹  ì§ì ‘ ê²€ìƒ‰í•˜ê¸° ìœ„í•´ vectorstore ë°˜í™˜
    return vectorstore


def merge_and_rerank_documents(
    docs_list: List[List[Document]], 
    top_k: int = 5
) -> List[Document]:
    """
    ì—¬ëŸ¬ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë³‘í•©í•˜ê³  ìœ ì‚¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ë ¬
    
    Args:
        docs_list: ê° ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë“¤
        top_k: ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
    
    Returns:
        ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ìƒìœ„ kê°œ ë¬¸ì„œ
    """
    all_docs = []
    
    # ëª¨ë“  ë¬¸ì„œ ìˆ˜ì§‘ (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨)
    for docs in docs_list:
        all_docs.extend(docs)
    
    # ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ì •ë ¬ (Document ê°ì²´ì— metadata['score'] ìˆë‹¤ê³  ê°€ì •)
    # ChromaDBì˜ similarity_search_with_score ì‚¬ìš© ì‹œ score í¬í•¨ë¨
    sorted_docs = sorted(
        all_docs, 
        key=lambda x: x.metadata.get('score', 0),
        reverse=True
    )
    
    return sorted_docs[:top_k]


def retrieve_documents(
    knowledge_names: List[str], 
    question: str, 
    top_k_per_knowledge: int = 3,
    final_top_k: int = 5
) -> Tuple[List[Document], Dict[str, int]]:
    """
    Multi-Knowledge Retrieval: ë³µìˆ˜ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰ ë° ë³‘í•©
    
    Args:
        knowledge_names: ê²€ìƒ‰í•  ì§€ì‹ë² ì´ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        question: ì‚¬ìš©ì ì§ˆë¬¸
        top_k_per_knowledge: ê° ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¬ ë¬¸ì„œ ê°œìˆ˜
        final_top_k: ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
    
    Returns:
        (ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸, ì§€ì‹ë³„ ë¬¸ì„œ ê°œìˆ˜ í†µê³„)
    """
    docs_list = []
    knowledge_stats = {name: 0 for name in knowledge_names}
    
    # ê° ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰
    for knowledge_name in knowledge_names:
        try:
            vectorstore = get_retriever(knowledge_name, top_k_per_knowledge)
            
            # ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰
            docs_with_scores = vectorstore.similarity_search_with_score(
                question, 
                k=top_k_per_knowledge
            )
            
            # Document ê°ì²´ì— score ë©”íƒ€ë°ì´í„° ì¶”ê°€
            docs = []
            for doc, score in docs_with_scores:
                doc.metadata['score'] = score
                doc.metadata['knowledge_name'] = knowledge_name
                docs.append(doc)
            
            docs_list.append(docs)
            
        except Exception as e:
            print(f"Warning: '{knowledge_name}'ì—ì„œ ê²€ìƒ‰ ì‹¤íŒ¨ - {str(e)}")
            continue
    
    # ë¬¸ì„œ ë³‘í•© ë° ì¬ì •ë ¬
    if not docs_list:
        return [], knowledge_stats
    
    final_docs = merge_and_rerank_documents(docs_list, final_top_k)
    
    # í†µê³„ ì§‘ê³„
    for doc in final_docs:
        kb_name = doc.metadata.get('knowledge_name', 'unknown')
        if kb_name in knowledge_stats:
            knowledge_stats[kb_name] += 1
    
    return final_docs, knowledge_stats


def generate_answer(
    documents: List[Document], 
    question: str,
    model_name: str = "gpt-4o-mini"
) -> Dict[str, Any]:
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ GPTë¥¼ ì´ìš©í•´ ë‹µë³€ ìƒì„±
    
    Args:
        documents: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        question: ì‚¬ìš©ì ì§ˆë¬¸
        model_name: ì‚¬ìš©í•  OpenAI ëª¨ë¸
    
    Returns:
        {
            'answer': ìƒì„±ëœ ë‹µë³€,
            'sources': ì¶œì²˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        }
    """
    if not documents:
        return {
            'answer': "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            'sources': []
        }
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_parts = []
    sources = []
    
    for i, doc in enumerate(documents, 1):
        # ì¶œì²˜ ì •ë³´ ì¶”ì¶œ
        source_info = {
            'index': i,
            'knowledge_name': doc.metadata.get('knowledge_name', 'Unknown'),
            'source_file': doc.metadata.get('source', 'Unknown'),
            'page': doc.metadata.get('page', 'N/A'),
            'score': doc.metadata.get('score', 0),
            'content_preview': doc.page_content[:100] + '...' if len(doc.page_content) > 100 else doc.page_content
        }
        sources.append(source_info)
        
        # ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        context_parts.append(f"[ì¶œì²˜ {i}]\n{doc.page_content}")
    
    context = "\n\n".join(context_parts)
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”:
1. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
3. ë‹µë³€í•  ë•Œ ì–´ëŠ ì¶œì²˜ì—ì„œ ê°€ì ¸ì˜¨ ì •ë³´ì¸ì§€ [ì¶œì²˜ ë²ˆí˜¸]ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
4. í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
5. ê°€ëŠ¥í•œ í•œ ìì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”. ì˜ˆì‹œì™€ ì„¸ë¶€ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”.
6. ê° ì£¼ìš” í¬ì¸íŠ¸ë¥¼ ì¶©ë¶„íˆ ì„¤ëª…í•˜ê³ , í•„ìš”í•˜ë‹¤ë©´ ì—¬ëŸ¬ ë¬¸ë‹¨ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì‘ì„±í•˜ì„¸ìš”. 
7. ì»¨í…ìŠ¤íŠ¸ì— ë‹µì´ ì—†ë‹¤ë©´ ì†”ì§íˆ "ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë§í•˜ì„¸ìš”."""),
        ("user", """ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:""")
    ])
    
    # LLM í˜¸ì¶œ
    llm = ChatOpenAI(model=model_name, temperature=0)
    chain = prompt_template | llm
    
    response = chain.invoke({
        "context": context,
        "question": question
    })
    
    return {
        'answer': response.content,
        'sources': sources
    }


def answer_question(
    knowledge_names: List[str],
    question: str,
    top_k_per_knowledge: int = 3,
    final_top_k: int = 5,
    use_reasoning_model: bool = False
) -> Dict[str, Any]:
    """
    RAG ì „ì²´ íŒŒì´í”„ë¼ì¸: ì§ˆë¬¸ â†’ ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±
    
    Args:
        knowledge_names: ê²€ìƒ‰í•  ì§€ì‹ë² ì´ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        question: ì‚¬ìš©ì ì§ˆë¬¸
        top_k_per_knowledge: ê° ì§€ì‹ì—ì„œ ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
        final_top_k: ìµœì¢… ì‚¬ìš©í•  ë¬¸ì„œ ìˆ˜
        use_reasoning_model: Trueë©´ GPT-4, Falseë©´ gpt-4o-mini
    
    Returns:
        {
            'answer': ë‹µë³€,
            'sources': ì¶œì²˜ ì •ë³´,
            'knowledge_stats': ì§€ì‹ë³„ ì‚¬ìš© ë¬¸ì„œ ê°œìˆ˜
        }
    """
    if use_reasoning_model:
        model_name = "gpt-4"
        print("ğŸ§  ì¶”ë¡  ëª¨ë“œ: GPT-4 ì‚¬ìš©")
    else:
        model_name = "gpt-4o-mini"
        
    # 1. ë¬¸ì„œ ê²€ìƒ‰
    documents, knowledge_stats = retrieve_documents(
        knowledge_names=knowledge_names,
        question=question,
        top_k_per_knowledge=top_k_per_knowledge,
        final_top_k=final_top_k
    )
    
    # 2. ë‹µë³€ ìƒì„±
    result = generate_answer(
        documents=documents,
        question=question,
        model_name=model_name
    )
    
    # 3. í†µê³„ ì¶”ê°€
    result['knowledge_stats'] = knowledge_stats
    
    return result